# -*- coding: utf-8 -*-
"""EEG Classification Code

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/mdsyednur/eeg-classification-code.8df93a83-2b5b-4b6e-b18d-aa54c2922aa2.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250820/auto/storage/goog4_request%26X-Goog-Date%3D20250820T072816Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D5809995dd5fdd02a491527a4a2792454e6bdc47a9e83d77650e2fd9c62b149206ba921a4af2cc7b27da8e53ceed8954da56e6f786584a59ac030eebdf9e5cbe88c871f986fe32c112dfc87a4d535e100106568a0a9895112f9f06e8c2eb7fee2fd93a0cd8a0a55a0f683b8667eb581346270c26ed13adc7375c14b41c2fdcbc759152c4efce64f6c65fa353494ab363ec3cd46dc67049be96babdc0e07d993e40ecf9ea8c4f8d9240a5d9895d358487352a2e79feea5dda0f4446f1d07e25c67a87aee659773a71b1b1e4c1c425a56f019340c78004cebbaa7427f419d843468ab5ead98b3a0a9e0c318a0379f2620b37a000af5b141866b774b4e7258f8acf5
"""

# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE
# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.
#import kagglehub
#kagglehub.login()
from datasets import load_dataset

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

dataset = load_dataset('DavidVivancos/MindBigData2023_MNIST-8B')

print('Data source import complete.')

"""**Step 0: Setup & imports**"""

import pandas as pd

# Load CSV
df = dataset['train'].to_pandas()

# Get only the first 128 EEG channels (adjust slicing if channels start after some metadata columns)
channel_names = df.columns[:128].tolist()

# Print the list
print(channel_names)

import pandas as pd

# Load just the header row (faster)
df = df.head(1)

# Extract base channel names (everything before the underscore)
base_channels = sorted(set(col.split('_')[0] for col in df.columns))

print(f"Total unique base channels: {len(base_channels)}\n")
print(base_channels)

import pandas as pd

#df = pd.read_csv("/kaggle/input/eeg-dataset-final/train30.csv", nrows=1)

non_channels = {"blocknum", "blockpos", "label", "sessionnum", "timestamp"}

channels = sorted(set(col.split('_')[0] for col in df.columns if col.split('_')[0] not in non_channels))

print(f"Total EEG channels: {len(channels)}")
print(channels)

import os
os.environ["CUDA_LAUNCH_BLOCKING"] = "1"  # make CUDA errors synchronous for debugging

import random
import numpy as np
import pandas as pd
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader, random_split
from collections import Counter
from scipy.signal import butter, sosfiltfilt
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from transformers import ViTConfig, ViTModel
import os 


# seed
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

"""**STEP 1: CONFIG**"""

TRAIN_CSV = dataset['train']
TEST_CSV = dataset['test']
LABEL_COL = "label"
SELECTED_CHANNELS = ["FPz", "F8", "FFT8h", "FT7", "FC5", "FC1", "FTT9h", "FTT8h", "T7", "P7", "P8", "T8"]

# Filtering
FS = 128
BANDPASS_LOW = 3.0
BANDPASS_HIGH = 30.0

# ERP/interpolation
CORR_THRESHOLD = 0.05
MIN_GOOD_CHANNELS = 1

# Training / model
MIXUP_ALPHA = 0.4
BATCH_SIZE = 32
VAL_SPLIT = 0.1
EPOCHS = 50
LR = 1e-4
EARLY_STOPPING_PATIENCE = 10

# ViT params
HIDDEN_SIZE = 256
NUM_LAYERS = 6
NUM_HEADS = 8
MLP_DIM = 512
DROPOUT = 0.1
MAX_TIME_PATCH = 32


"""**New addition**"""

num_cpus=os.cpu_count()
num_workers=min(num_cpus, 8)
print(f"Creating Dataloaders with {num_workers} workers.....")

"""** STEP 2: PREPROCESSING FUNCTIONS**"""

# ===== updated helpers =====

# ===== NEW BATCH PREPROCESSING FUNCTION =====

def preprocess_batch(batch):
    """
    This function takes a batch of data from the Hugging Face dataset,
    assembles the required channels into a NumPy array, and applies
    all the preprocessing steps.
    """
    # 1. Assemble selected channels into a NumPy array (N, C, T)
    per_channel = []
    for ch_prefix in SELECTED_CHANNELS:
        # Find all columns for the current channel prefix, e.g., 'FPz_0', 'FPz_1', ...
        cols = sorted([c for c in batch.keys() if c.startswith(f"{ch_prefix}_")])
        
        # Stack the values from these columns to form a (num_samples, time_length) array
        channel_data = np.stack([batch[c] for c in cols], axis=1)
        per_channel.append(channel_data[:, None, :]) # Add a dimension for concatenation

    X = np.concatenate(per_channel, axis=1) # Shape: (batch_size, num_channels, time_length)

    # 2. Apply the same preprocessing steps as before
    X = apply_bandpass(X)
    X = remove_dc(X)
    X = baseline_correct(X, pre_stim_samples=50)
    X_final = normalize_per_trial_channel(X)

    # 3. Return the processed data and the label in a dictionary
    batch['processed_eeg'] = X_final
    return batch

def load_selected_channels(path, selected_channel_prefixes, label_col=LABEL_COL):
    #df = pd.read_csv(path)
    if label_col not in df.columns:
        raise ValueError(f"Label column '{label_col}' missing in {path}")
    y = df[label_col].to_numpy()
    per_channel = []
    lengths = []
    for ch in selected_channel_prefixes:
        cols = sorted([c for c in df.columns if c.startswith(f"{ch}_")])
        if not cols:
            raise ValueError(f"No columns for channel {ch} in {path}")
        arr = df[cols].to_numpy()  # (N, T_ch)
        per_channel.append(arr)
        lengths.append(arr.shape[1])
    min_T = min(lengths)
    trimmed = []
    for arr in per_channel:
        trimmed.append(arr[:, :min_T][:, None, :])  # (N,1,min_T)
    X = np.concatenate(trimmed, axis=1)  # (N, C_selected, min_T)
    return X, y

def make_bandpass(low, high, fs, order=4):
    return butter(order, [low, high], btype="bandpass", fs=fs, output="sos")

def apply_bandpass(X, fs=FS, low=BANDPASS_LOW, high=BANDPASS_HIGH):
    sos = make_bandpass(low, high, fs)
    N, C, T = X.shape
    out = np.zeros_like(X)
    for i in range(N):
        for ch in range(C):
            out[i, ch, :] = sosfiltfilt(sos, X[i, ch, :])
    return out

def remove_dc(X):
    return X - X.mean(axis=2, keepdims=True)

def baseline_correct(X, pre_stim_samples=50):
    # subtract pre-stimulus mean (first few samples) per trial-channel
    baseline = X[:, :, :pre_stim_samples].mean(axis=2, keepdims=True)
    return X - baseline

def compute_erp_by_class_channel(X, y):
    erps = {}
    for cls in np.unique(y):
        erps[cls] = {}
        idxs = np.where(y == cls)[0]
        if len(idxs) == 0:
            continue
        for ch in range(X.shape[1]):
            erps[cls][ch] = X[idxs, ch, :].mean(axis=0)
    return erps

def compute_good_mask_and_corr_with_given_erps(X, y, erps, threshold=CORR_THRESHOLD):
    N, C, T = X.shape
    good_mask = np.zeros((N, C), dtype=bool)
    corr_vals = np.zeros((N, C), dtype=float)
    for i in range(N):
        cls = y[i]
        for ch in range(C):
            trial = X[i, ch, :]
            template = erps.get(cls, {}).get(ch, np.zeros(T))
            if np.std(trial) == 0 or np.std(template) == 0:
                corr = 0.0
            else:
                corr = np.corrcoef(trial, template)[0,1]
            corr_vals[i, ch] = corr
            good_mask[i, ch] = corr >= threshold
    return good_mask, corr_vals

def interpolate_with_condition_fallback(X, y, good_mask, erps, min_good=MIN_GOOD_CHANNELS):
    X_rep = X.copy()
    N, C, T = X.shape
    candidates = {}
    for cls in np.unique(y):
        candidates[cls] = {}
        idxs = np.where(y == cls)[0]
        for ch in range(C):
            good_idxs = [i for i in idxs if good_mask[i, ch]]
            candidates[cls][ch] = good_idxs

    for i in range(N):
        cls = y[i]
        for ch in range(C):
            if good_mask[i, ch]:
                continue
            pool = candidates[cls][ch]
            if len(pool) > 0:
                replacement = random.choice(pool)
                X_rep[i, ch, :] = X[replacement, ch, :]
            else:
                # fallback: class ERP template
                if cls in erps and ch in erps[cls]:
                    X_rep[i, ch, :] = erps[cls][ch]
                # else leave as-is (should be rare)
    return X_rep

def normalize_per_trial_channel(X, eps=1e-6):
    Xn = np.zeros_like(X)
    N, C, T = X.shape
    for i in range(N):
        for ch in range(C):
            ts = X[i, ch, :]
            mu = ts.mean()
            sigma = ts.std()
            Xn[i, ch, :] = (ts - mu) / (sigma + eps)
    return Xn

"""**STEP 3: LOAD & APPLY PAPER PREPROCESSING**"""

# --- STEP 3: LOAD & APPLY PAPER PREPROCESSING (updated) ---


# --- COMBINED AND CORRECTED STEP 3 & 4: Process Data in One Pass ---

import numpy as np
from collections import Counter

print("Starting chunk-based preprocessing...")

# Step 3.1: Find unique labels and create the mapping
# This part is memory-efficient and stays the same.
print("Finding unique labels by iterating through the dataset...")
unique_labels_set = set()
for example in dataset['train']:
    if example['label'] != -1: # We only care about valid labels
        unique_labels_set.add(example['label'])

unique_labels = sorted(list(unique_labels_set))
label_map = {label: i for i, label in enumerate(unique_labels)}
NUM_CLASSES = len(unique_labels)
print(f"Found {NUM_CLASSES} unique classes. Mapping: {label_map}")


# Step 3.2: Define a SINGLE, powerful preprocessing function
# This function now also filters, remaps labels, and processes EEG data.
def filter_remap_and_preprocess_batch(batch):
    # --- Part 1: Filter and Remap Labels ---
    indices_to_keep = []
    remapped_labels = []
    
    # Go through the labels in the batch one by one
    for i, label in enumerate(batch['label']):
        if label in label_map: # Check if the label is valid
            indices_to_keep.append(i)
            remapped_labels.append(label_map[label]) # Remap the valid label

    if not indices_to_keep: # If the whole batch is invalid, return None
        return None

    # --- Part 2: Assemble EEG data ONLY for the valid trials ---
    per_channel = []
    for ch_prefix in SELECTED_CHANNELS:
        cols = sorted([c for c in batch.keys() if c.startswith(f"{ch_prefix}_")])
        # Select only the rows (indices) that have valid labels
        channel_data = np.stack([batch[c] for c in cols], axis=1)[indices_to_keep]
        per_channel.append(channel_data[:, None, :])

    X = np.concatenate(per_channel, axis=1)

    # --- Part 3: Apply EEG preprocessing ---
    X = apply_bandpass(X)
    X = remove_dc(X)
    X = baseline_correct(X, pre_stim_samples=50)
    X_final = normalize_per_trial_channel(X)

    # Return a new dictionary with the processed data
    return {"processed_eeg": X_final, "label": remapped_labels}


# --- Corrected Step 3.3: Apply the single function to each split ---

print("Applying filtering, remapping, and EEG preprocessing in a single pass...")

# Get the list of original columns to remove
original_columns = dataset['train'].column_names

# Create a new dictionary to store the processed splits
processed_splits = {}

# Loop through each split in the original dataset (e.g., 'train', 'test')
for split_name, split_data in dataset.items():
    print(f"Processing '{split_name}' split...")
    processed_splits[split_name] = split_data.map(
        filter_remap_and_preprocess_batch,
        batched=True,
        batch_size=50,  # Keep your small batch size
        remove_columns=original_columns,
        num_proc = 1
    )

# Recreate the DatasetDict from the processed splits
from datasets import DatasetDict
processed_dataset = DatasetDict(processed_splits)


print("Preprocessing complete.")
print("New dataset features:", processed_dataset['train'].features)

# (Optional) Check the distribution of the final labels
final_train_labels = processed_dataset['train']['label']
print("Final Train class counts:", Counter(final_train_labels))


# Step 4: Finalize the dataset format for PyTorch
print("Setting dataset format to PyTorch tensors...")
processed_dataset.set_format(
    type='torch', columns=['processed_eeg', 'label']
)

"""**STEP 5: DATASET + MIXUP**"""

class EEGDataset(Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y.astype(int)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        x = torch.from_numpy(self.X[idx]).float()  # (C, T)
        y = torch.tensor(self.y[idx]).long()
        return x, y

def apply_mixup(x, y, alpha=0.4, use_mixup=True):
    """
    x: Tensor (B, C, T)
    y: Tensor (B,)
    Returns: mixed_x, y_a, y_b, lam
    """
    if not use_mixup or alpha <= 0:
        return x, y, y, 1.0
    lam = np.random.beta(alpha, alpha)
    lam = max(lam, 1 - lam)  # optional: enforce lam >= 0.5 to keep label dominance (can remove if you want full symmetry)
    batch_size = x.size(0)
    index = torch.randperm(batch_size, device=x.device)
    x_shuffled = x[index]
    y_shuffled = y[index]
    mixed_x = lam * x + (1 - lam) * x_shuffled
    return mixed_x, y, y_shuffled, lam

"""**STEP 6: MODEL**"""

"""**New ModeL**"""
"""


def choose_patch_size(n_channels, time_length, max_time_patch=MAX_TIME_PATCH):
    channel_patch = 1
    time_patch = next((d for d in range(max_time_patch, 0, -1) if time_length % d == 0), 1)
    return (channel_patch, time_patch)

class EEGViT(nn.Module):
    def __init__(self, n_channels, time_length, num_classes,
                 hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS,
                 num_heads=NUM_HEADS, mlp_dim=MLP_DIM, dropout=DROPOUT):
        super().__init__()
        patch_size = choose_patch_size(n_channels, time_length)
        config = ViTConfig(
            hidden_size=hidden_size, num_hidden_layers=num_layers,
            num_attention_heads=num_heads, intermediate_size=mlp_dim,
            hidden_dropout_prob=dropout, attention_probs_dropout_prob=dropout,
            image_size=(n_channels, time_length), patch_size=patch_size,
            num_channels=1, classifier_dropout=dropout, return_dict=True
        )
        self.vit = ViTModel(config)
        self.classifier = nn.Sequential(nn.LayerNorm(hidden_size), nn.Linear(hidden_size, num_classes))
    def forward(self, x):
        img = x.unsqueeze(1)  # (B,1,C,T)
        pooled = self.vit(pixel_values=img).pooler_output
        return self.classifier(pooled)

class EEGViTPretrained(nn.Module):
    def __init__(self, model_name="google/vit-base-patch16-224",
                 image_size=(12,500), patch_size=(1,25),
                 num_classes=10, classifier_intermediate=512):
        super().__init__()
        config = ViTConfig.from_pretrained(model_name)
        config.num_channels=1; config.image_size=image_size; config.patch_size=patch_size
        config.num_labels=num_classes
        self.model = ViTForImageClassification.from_pretrained(model_name, config=config, ignore_mismatched_sizes=True)
        embed_dim = self.model.vit.config.hidden_size
        self.model.classifier = nn.Sequential(
            nn.Linear(embed_dim, classifier_intermediate), nn.ReLU(), nn.Dropout(0.1),
            nn.Linear(classifier_intermediate, num_classes)
        )
    def forward(self, x):
        img = x.unsqueeze(1)
        return self.model(pixel_values=img).logits

"""


"""**EEGNetModel**"""

# --- [ADD THIS TO STEP 6] ---

import torch
import torch.nn as nn

class EEGNet(nn.Module):
    """
    A PyTorch implementation of the EEGNet model from:
    "EEGNet: A Compact Convolutional Neural Network for EEG-based
    Brain-Computer Interfaces"
    https://arxiv.org/pdf/1611.08024.pdf
    """
    def __init__(self, num_classes, n_channels, time_length, dropout_rate=0.5):
        super(EEGNet, self).__init__()
        
        # --- Layer 1: Temporal Convolution ---
        # This block learns frequency filters.
        # Input: (B, 1, C, T)
        # Output: (B, F1, C, T)
        self.F1 = 8
        self.conv1 = nn.Conv2d(1, self.F1, (1, 64), padding=(0, 32), bias=False)
        self.batchnorm1 = nn.BatchNorm2d(self.F1, momentum=0.01)
        
        # --- Layer 2: Depthwise Spatial Convolution ---
        # This block learns spatial filters for channel combinations.
        # Input: (B, F1, C, T)
        # Output: (B, F1 * D, 1, T)
        self.D = 2
        self.conv2 = nn.Conv2d(self.F1, self.F1 * self.D, (n_channels, 1), groups=self.F1, bias=False)
        self.batchnorm2 = nn.BatchNorm2d(self.F1 * self.D, momentum=0.01)
        self.elu = nn.ELU()
        self.avgpool1 = nn.AvgPool2d((1, 4)) # Output: (B, F1 * D, 1, T/4)
        self.dropout1 = nn.Dropout(dropout_rate)
        
        # --- Layer 3: Separable Convolution ---
        # This block learns temporal features from the spatially-filtered data.
        # Input: (B, F1 * D, 1, T/4)
        # Output: (B, F2, 1, T/32)
        self.F2 = self.F1 * self.D  # = 16
        self.conv3_separable = nn.Sequential(
            # Depthwise conv
            nn.Conv2d(self.F2, self.F2, (1, 16), padding=(0, 8), groups=self.F2, bias=False),
            # Pointwise conv
            nn.Conv2d(self.F2, self.F2, (1, 1), bias=False),
            nn.BatchNorm2d(self.F2, momentum=0.01),
            nn.ELU(),
            nn.AvgPool2d((1, 8)), # Output: (B, F2, 1, T/32)
            nn.Dropout(dropout_rate)
        )
        
        # --- Classifier Head ---
        # We need to calculate the final flattened feature size.
        # We do this by running a dummy tensor through the feature extractor.
        with torch.no_grad():
            dummy_input = torch.zeros(1, 1, n_channels, time_length)
            final_feature_size = self._get_feature_size(dummy_input)
            
        self.classifier = nn.Linear(final_feature_size, num_classes)

    def _get_feature_size(self, x):
        """Helper function to calculate the feature size for the classifier"""
        x = self.conv1(x)
        x = self.batchnorm1(x)
        x = self.conv2(x)
        x = self.batchnorm2(x)
        x = self.elu(x)
        x = self.avgpool1(x)
        x = self.dropout1(x)
        x = self.conv3_separable(x)
        return x.view(x.size(0), -1).shape[1]

    def forward(self, x):
        """
        Input x has shape (Batch_Size, Num_Channels, Time_Length), e.g., (32, 12, 500)
        """
        
        # We must add a singleton "input channel" dimension for the 2D Convs
        # Shape becomes (B, 1, C, T), e.g., (32, 1, 12, 500)
        x = x.unsqueeze(1)
        
        # Feature extraction
        x = self.conv1(x)
        x = self.batchnorm1(x)
        x = self.conv2(x)
        x = self.batchnorm2(x)
        x = self.elu(x)
        x = self.avgpool1(x)
        x = self.dropout1(x)
        
        x = self.conv3_separable(x)
        
        # Flatten for the classifier
        # Shape becomes (B, F2 * (T/32))
        x = x.view(x.size(0), -1)
        
        # Classifier
        x = self.classifier(x)
        return x

"""**Old MODEL**"""

"""
from transformers import ViTConfig, ViTModel  # ensure this is near top of file

def choose_patch_size(n_channels, time_length, max_time_patch=MAX_TIME_PATCH):
    
#Keep channel patch =1 (we don't split channels), choose largest time_patch dividing time_length
#   so that we get reasonable tokenization.
    
    channel_patch = 1
    time_patch = next((d for d in range(max_time_patch, 0, -1) if time_length % d == 0), 1)
    return (channel_patch, time_patch)

class EEGViT(nn.Module):
    def __init__(self, n_channels, time_length, num_classes, patch_size=None,
                 hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS,
                 num_heads=NUM_HEADS, mlp_dim=MLP_DIM, dropout=DROPOUT):
        super().__init__()
        if patch_size is None:
            patch_size = choose_patch_size(n_channels, time_length)
        ch_patch, time_patch = patch_size
        if not (n_channels % ch_patch == 0 and time_length % time_patch == 0):
            corrected = choose_patch_size(n_channels, time_length)
            warnings.warn(f"Incompatible patch_size {patch_size}; switching to {corrected}.")
            patch_size = corrected
            ch_patch, time_patch = patch_size

        # Build ViT config for the "image" of shape (n_channels, time_length) with a single input channel
        config = ViTConfig(
            hidden_size=hidden_size,
            num_hidden_layers=num_layers,
            num_attention_heads=num_heads,
            intermediate_size=mlp_dim,
            hidden_dropout_prob=dropout,
            attention_probs_dropout_prob=dropout,
            image_size=(n_channels, time_length),
            patch_size=patch_size,
            num_channels=1,
            classifier_dropout=dropout,
            return_dict=True,
        )

        self.vit = ViTModel(config)
        self.classifier = nn.Sequential(
            nn.LayerNorm(hidden_size),
            nn.Linear(hidden_size, num_classes)
        )

    def forward(self, x):
        
#   x: (B, C, T) where C is channels (e.g., 4), T is time length.
#       Expand to (B,1,C,T) to match ViT expected (B, num_channels, H, W).
        
        img = x.unsqueeze(1)  # (B,1,channels,time)
        outputs = self.vit(pixel_values=img)
        pooled = outputs.pooler_output  # (B, hidden_size)
        return self.classifier(pooled)

"""

"""**STEP 7: TRAINING & EVAL SETUP**"""

# --- STEP 7: TRAINING & EVAL SETUP (OPTIMIZED FOR CHUNKED DATA) ---

from torch.utils.data import DataLoader
from collections import Counter
import torch
import torch.nn as nn
import numpy as np
from datasets import ClassLabel # <--- ADD THIS IMPORT

print("\nSetting up training and evaluation...")

# --- NEW CODE TO FIX THE ERROR ---
# Cast the 'label' column to the ClassLabel type required for stratification.
print("Casting 'label' column to ClassLabel type...")
class_names = [str(i) for i in range(NUM_CLASSES)]
processed_dataset = processed_dataset.cast_column(
    'label', ClassLabel(num_classes=NUM_CLASSES, names=class_names)
)
# --------------------------------

# Step 7.1: Split the training data into training and validation sets
# This line will now work correctly.
print(f"Splitting the training data ({VAL_SPLIT*100}% for validation)...")
split_dataset = processed_dataset['train'].train_test_split(
    test_size=VAL_SPLIT, stratify_by_column='label', seed=SEED
)
train_dataset = split_dataset['train']
val_dataset = split_dataset['test']
test_dataset = processed_dataset['test'] # The original test set


print(f"Train samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}, Test samples: {len(test_dataset)}")

# Step 7.2: Define a custom collate function for the DataLoader
# This tells PyTorch how to combine a list of dictionary items into a single batch.
def collate_fn(examples):
    # 'processed_eeg' holds our EEG data tensors
    eeg_tensors = torch.stack([example["processed_eeg"] for example in examples])
    # 'label' holds our label tensors
    label_tensors = torch.tensor([example["label"] for example in examples])
    return eeg_tensors, label_tensors

# Step 7.3: Create the DataLoaders
#num_cpus = os.cpu_count()
#num_workers = min(num_cpus, 8)
#print(f"Crearting DataLoader with {num_workers} workers....")

#print("Creating DataLoaders...")
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=num_workers, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=num_workers, pin_memory=True)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=num_workers, pin_memory=True)

# Step 7.4: Instantiate the model
# Get the shape of the data from the first sample.
sample_eeg = train_dataset[0]['processed_eeg']
n_channels = sample_eeg.shape[0]
time_length = sample_eeg.shape[1]
#patch_size = choose_patch_size(n_channels, time_length)

print(f"Instantiating model for EEG shape ({n_channels}, {time_length}) with {NUM_CLASSES} classes.")
#print(f"Using patch_size: {patch_size}")

# Initialize either the from-scratch model or the pretrained one.
# Make sure the class definition for EEGViT or EEGViTPretrained exists before this step.
#model = EEGViT(
#    n_channels=n_channels,
#    time_length=time_length,
#    num_classes=NUM_CLASSES,
#    #patch_size=patch_size
#).to(device)
# To use the pretrained model instead, uncomment the following lines:
"""

 model = EEGViTPretrained(
     image_size=(n_channels, time_length),
     patch_size=patch_size,
     num_classes=NUM_CLASSES
 ).to(device)
"""

print("Using EEGNet model...")
model = EEGNet(
    num_classes=NUM_CLASSES,
    n_channels=n_channels,
    time_length=time_length,
    dropout_rate=DROPOUT  # Using the DROPOUT=0.1 from your config
).to(device)



# Step 7.5: Define Loss Function (with class weights) and Optimizer
print("Setting up loss function with class weighting...")

# To handle class imbalance, we calculate weights based on the training split's composition.
train_labels = train_dataset['label']
train_counts = Counter(train_labels)

def make_class_weight_tensor_from_counts(counts, device):
    num_classes_local = max(counts.keys()) + 1
    weights = torch.ones(num_classes_local, device=device)
    total_samples = sum(counts.values())
    for cls, cnt in counts.items():
        if cnt > 0:
            # Formula: N_samples / (N_classes * N_samples_class_i)
            weights[cls] = total_samples / (len(counts) * cnt)
    return weights

class_weights = make_class_weight_tensor_from_counts(train_counts, device)
print(f"Calculated class weights: {class_weights.cpu().numpy()}")
criterion = nn.CrossEntropyLoss(weight=class_weights)
optimizer = torch.optim.Adam(model.parameters(), lr=LR)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode="max", factor=0.5, patience=5, verbose=True)

# Step 7.6: Define the Evaluation Helper Function
def evaluate(model, loader):
    model.eval()
    all_preds, all_labels = [], []
    with torch.no_grad():
        for xb, yb in loader:
            xb = xb.to(device)
            yb = yb.to(device)
            logits = model(xb)
            preds = logits.argmax(dim=1)
            all_preds.append(preds.cpu().numpy())
            all_labels.append(yb.cpu().numpy())
    return np.concatenate(all_labels), np.concatenate(all_preds)

print("Setup complete. Ready for training.")

"""**STEP 8: TRAIN LOOP**"""

best_val_acc = 0.0
stale = 0
history = {"train_loss": [], "train_acc": [], "val_acc": []}

for epoch in range(1, EPOCHS + 1):
    model.train()
    total_loss = 0.0
    correct = 0
    total = 0

    for xb, yb in train_loader:
        xb = xb.to(device)
        yb = yb.to(device)

        # sanity check
        if (yb < 0).any() or (yb >= NUM_CLASSES).any():
            print("Bad labels:", torch.unique(yb))
            raise RuntimeError("Label out of range")

        # apply mixup explicitly
        mixed_x, y_a, y_b, lam = apply_mixup(xb, yb, alpha=MIXUP_ALPHA, use_mixup=True)
        logits = model(mixed_x)
        loss = lam * criterion(logits, y_a) + (1 - lam) * criterion(logits, y_b)

        optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # optional stabilizer
        optimizer.step()

        total_loss += loss.item() * xb.size(0)

        # compute accuracy on original (non-mixed) inputs for reporting
        with torch.no_grad():
            orig_logits = model(xb)
            preds = orig_logits.argmax(dim=1)
            correct += (preds == yb).sum().item()
        total += xb.size(0)

    train_loss = total_loss / total
    train_acc = correct / total

    # validation
    y_val, preds_val = evaluate(model, val_loader)
    val_acc = (preds_val == y_val).mean()

    # scheduler step
    scheduler.step(val_acc)

    history["train_loss"].append(train_loss)
    history["train_acc"].append(train_acc)
    history["val_acc"].append(val_acc)

    # checkpointing / early stopping
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        stale = 0
        torch.save(model.state_dict(), f"best_eegvit_val{val_acc:.4f}.pth")
    else:
        stale += 1

    print(f"[Epoch {epoch:02d}] train_loss={train_loss:.4f} train_acc={train_acc:.4f} val_acc={val_acc:.4f} best={best_val_acc:.4f} stale={stale}")
    if stale >= EARLY_STOPPING_PATIENCE:
        print("Early stopping.")
        break

"""**STEP 9: FINAL EVALUATION**"""

# === Imports (safe re-imports) ===
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    classification_report, confusion_matrix, balanced_accuracy_score
)

# === Evaluate and print headline metrics ===
y_true, y_pred = evaluate(model, test_loader)  # your existing eval
classes = np.unique(y_true)
class_names = [str(c) for c in classes]  # or your own label names

acc = (y_pred == y_true).mean()
bal_acc = balanced_accuracy_score(y_true, y_pred)
print(f"Test Accuracy: {acc:.4f}")
print(f"Balanced Accuracy: {bal_acc:.4f}\n")

# Text report (nice to keep for logs)
print("Classification Report:\n",
      classification_report(y_true, y_pred, digits=4, zero_division=0))

# === Confusion Matrix (Counts) ===
cm = confusion_matrix(y_true, y_pred, labels=classes)
plt.figure(figsize=(7, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=True,
            xticklabels=class_names, yticklabels=class_names)
plt.title("Confusion Matrix (Counts)")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.tight_layout()
plt.show()

# === Confusion Matrix (Normalized by true class) ===
cm_norm = cm.astype(float) / (cm.sum(axis=1, keepdims=True) + 1e-9)
plt.figure(figsize=(7, 6))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Blues", cbar=True,
            xticklabels=class_names, yticklabels=class_names)
plt.title("Confusion Matrix (Normalized by True Class)")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.tight_layout()
plt.show()

# === Per-class Precision / Recall / F1 (bar charts) ===
report_dict = classification_report(
    y_true, y_pred, output_dict=True, zero_division=0
)
# Keep only real classes; drop "accuracy", "macro avg", "weighted avg"
per_class_rows = {k: v for k, v in report_dict.items() if k in map(str, classes)}

per_class_df = pd.DataFrame(per_class_rows).T
# Ensure order matches classes
per_class_df = per_class_df.loc[list(map(str, classes))]

# Precision
plt.figure(figsize=(8, 4))
plt.bar(class_names, per_class_df["precision"].values)
plt.ylim(0, 1)
plt.title("Per-class Precision")
plt.xlabel("Class")
plt.ylabel("Precision")
plt.grid(axis="y", alpha=0.3)
plt.tight_layout()
plt.show()

# Recall
plt.figure(figsize=(8, 4))
plt.bar(class_names, per_class_df["recall"].values)
plt.ylim(0, 1)
plt.title("Per-class Recall")
plt.xlabel("Class")
plt.ylabel("Recall")
plt.grid(axis="y", alpha=0.3)
plt.tight_layout()
plt.show()

# F1-score
plt.figure(figsize=(8, 4))
plt.bar(class_names, per_class_df["f1-score"].values)
plt.ylim(0, 1)
plt.title("Per-class F1-score")
plt.xlabel("Class")
plt.ylabel("F1-score")
plt.grid(axis="y", alpha=0.3)
plt.tight_layout()
plt.show()

# === Training Curves (separate figures) ===
def smooth_curve(x, alpha=0.6):
    smoothed = []
    for i, v in enumerate(x):
        smoothed.append(v if i == 0 else alpha * v + (1 - alpha) * smoothed[-1])
    return smoothed

# Loss (if val_loss exists, plot it too)
plt.figure(figsize=(8, 4))
plt.plot(history["train_loss"], label="train_loss", linewidth=1)
plt.plot(smooth_curve(history["train_loss"]), "--", label="train_loss (smoothed)", linewidth=1)
if "val_loss" in history:
    plt.plot(history["val_loss"], label="val_loss", linewidth=1)
plt.title("Training Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.grid(alpha=0.3)
plt.legend()
plt.tight_layout()
plt.show()

# Accuracy (train vs val)
plt.figure(figsize=(8, 4))
plt.plot(history["train_acc"], label="train_acc", linewidth=1)
plt.plot(history["val_acc"], label="val_acc", linewidth=1)
plt.title("Training Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.grid(alpha=0.3)
plt.legend()
plt.tight_layout()
plt.show()

print("\n[viz] 2) Loss curves + final Train/Test CE")
viz_plot_loss_curves_and_final_losses()

print("\n[viz] 3) Accuracies + Test Confusion Matrix")
viz_eval_and_cm()

print("\n[viz] 4) Per-channel confusion matrices")
viz_per_channel_cms(save_dir="per_channel_cms", normalize=False)

print("\n[viz] 5) t-SNE (train vs test)")
viz_plot_tsne(max_points=3000, perplexity=30.0)

import torch
from torch import nn
from transformers import ViTConfig, ViTForImageClassification
import math
import torch.nn.functional as F

class ConvBn(nn.Module):
    def __init__(self, conv: nn.Conv2d, bn: nn.BatchNorm2d):
        super().__init__()
        self.conv = conv
        self.bn = bn

    def forward(self, x):
        x = self.conv(x)
        return self.bn(x)

    @property
    def weight(self):
        return self.conv.weight

    @property
    def bias(self):
        return self.conv.bias

def resize_positional_embeddings(model, new_grid_size):
    """
    Adapt positional embeddings to the target patch grid size.
    If original (non-CLS) embedding count is square, interpolate; else
    reinitialize positional embeddings for the new grid.
    new_grid_size: (H_patches, W_patches)
    """
    old_pos_embed = model.vit.embeddings.position_embeddings  # (1, old_num+1, dim)
    cls_token = model.vit.embeddings.cls_token  # (1,1,dim)
    embedding_dim = old_pos_embed.size(2)

    old_pos = old_pos_embed[:, 1:, :]  # exclude cls token
    old_num_tokens = old_pos.size(1)

    new_h, new_w = new_grid_size
    new_num_patches = new_h * new_w

    # Case 1: original tokens form square grid -> interpolate
    old_grid_size = int(math.isqrt(old_num_tokens))
    if old_grid_size * old_grid_size == old_num_tokens:
        old_grid = old_pos.transpose(1, 2).reshape(1, embedding_dim, old_grid_size, old_grid_size)
        new_grid = F.interpolate(old_grid, size=(new_h, new_w), mode="bicubic", align_corners=False)
        new_grid = new_grid.reshape(1, embedding_dim, new_h * new_w).transpose(1, 2)
        new_pos_embed = torch.cat([cls_token, new_grid], dim=1)  # (1, new_num+1, dim)
        model.vit.embeddings.position_embeddings = nn.Parameter(new_pos_embed)
        return

    # Case 2: fallbackâ€”reinitialize positional embeddings
    print(f"[resize_positional_embeddings] original token count {old_num_tokens} not square; reinitializing positional embeddings to ({new_h}, {new_w})")
    # Determine init scale
    std = getattr(model.vit.config, "initializer_range", 0.02)
    new_pos = torch.zeros(1, new_num_patches + 1, embedding_dim, device=old_pos_embed.device)
    nn.init.trunc_normal_(new_pos, mean=0.0, std=std, a=-2*std, b=2*std)
    new_pos[:, 0:1, :] = cls_token  # preserve original cls token
    model.vit.embeddings.position_embeddings = nn.Parameter(new_pos)


class EEGViTPretrained(nn.Module):
    def __init__(
        self,
        model_name="google/vit-base-patch16-224",
        image_size=(4, 500),        # (channels, time)
        patch_size=(1, 25),         # must divide image_size
        hidden_dropout_prob=0.1,
        attention_probs_dropout_prob=0.1,
        num_classes=10,
        classifier_intermediate=512,
    ):
        super().__init__()

        # Build custom config overriding necessary fields
        config = ViTConfig.from_pretrained(model_name)
        config.num_channels = 1  # since we feed (B,1,H,W)
        config.image_size = image_size  # height=channels, width=time
        config.patch_size = patch_size
        config.hidden_dropout_prob = hidden_dropout_prob
        config.attention_probs_dropout_prob = attention_probs_dropout_prob
        config.num_labels = num_classes  # for compatibility

        # Load model (with mismatch tolerated)
        self.model = ViTForImageClassification.from_pretrained(
            model_name,
            config=config,
            ignore_mismatched_sizes=True
        )

        # Replace patch embedding to accept single-channel EEG patches
        in_channels = 1
        embed_dim = self.model.vit.config.hidden_size

        conv = nn.Conv2d(
            in_channels,
            embed_dim,
            kernel_size=patch_size,
            stride=patch_size,
            padding=0,
            bias=False
        )
        bn = nn.BatchNorm2d(embed_dim)
        self.model.vit.embeddings.patch_embeddings.projection = ConvBn(conv, bn)

        # Resize or reinitialize positional embeddings
        grid_h = image_size[0] // patch_size[0]
        grid_w = image_size[1] // patch_size[1]
        resize_positional_embeddings(self.model, new_grid_size=(grid_h, grid_w))

        # Replace classifier head with a small MLP
        self.model.classifier = nn.Sequential(
            nn.Linear(embed_dim, classifier_intermediate),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1),
            nn.Linear(classifier_intermediate, num_classes)
        )

    def forward(self, x):
        """
        x: (B, C, T) -> expand to (B,1,C,T) to match ViT input layout (B, num_channels, H, W)
        Here we treat C as height and T as width.
        """
        img = x.unsqueeze(1)  # (B,1,channels,time)
        outputs = self.model(pixel_values=img)
        return outputs.logits  # (B, num_classes)

import numpy as np
import torch
from torch.utils.data import DataLoader

# ====== HELPER: choose valid patch size for EEG shape ======
def choose_eeg_patch_size(eeg_shape, max_time_patch=32):
    """
    eeg_shape: (channels, time)
    Returns patch_size (channel_patch, time_patch) where:
      - channel_patch is 1 (since small number of channels)
      - time_patch is the largest divisor of time <= max_time_patch
    """
    channels, time_length = eeg_shape
    channel_patch = 1
    time_patch = next((d for d in range(max_time_patch, 0, -1) if time_length % d == 0), 1)
    return (channel_patch, time_patch)

# === Load example data ===
X_example = np.load("X_train_clean.npy")  # shape (N, C, T)
y_example = np.load("y_train_clean.npy")
n_channels = X_example.shape[1]
time_length = X_example.shape[2]
eeg_shape = (n_channels, time_length)

# pick patch_size
patch_size = choose_eeg_patch_size(eeg_shape, max_time_patch=32)
print("Using patch_size:", patch_size, "for image size:", eeg_shape)

# instantiate pretrained ViT model for EEG
num_classes = int(np.unique(y_example).max()) + 1  # e.g., digits

model = EEGViTPretrained(
    image_size=eeg_shape,
    patch_size=patch_size,
    num_classes=num_classes
).to(device)

# Quick forward sanity check with one batch (no training yet)
dataset = EEGDataset(X_example, y_example)  # simplified dataset, no mixup inside
loader = DataLoader(dataset, batch_size=8, shuffle=False)
xb, yb = next(iter(loader))
xb = xb.to(device)
with torch.no_grad():
    logits = model(xb)  # should not error
print("Logits shape:", logits.shape)  # (B, num_classes)

import torch
from torch import nn
from torch.utils.data import DataLoader
import numpy as np
from collections import Counter
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

# --- hyperparams ---
BATCH_SIZE = 64
VAL_SPLIT = 0.1
EPOCHS = 80
LR = 1e-4
MIXUP_ALPHA = 0.0
EARLY_STOPPING_PATIENCE = 10
SEED = 42

# --- load cleaned data ---
X_train = np.load("X_train_clean.npy")  # (N, C, T)
y_train = np.load("y_train_clean.npy")
X_test = np.load("X_test_clean.npy")
y_test = np.load("y_test_clean.npy")

NUM_CLASSES = int(np.unique(y_train).max()) + 1

# --- simplified dataset (no internal mixup) ---
class EEGDataset(torch.utils.data.Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y.astype(int)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        x = torch.from_numpy(self.X[idx]).float()  # (C,T)
        y = torch.tensor(self.y[idx]).long()
        return x, y

def apply_mixup(x, y, alpha=0.4, use_mixup=True):
    if not use_mixup or alpha <= 0:
        return x, y, y, 1.0
    lam = np.random.beta(alpha, alpha)
    batch_size = x.size(0)
    index = torch.randperm(batch_size, device=x.device)
    x_shuffled = x[index]
    y_shuffled = y[index]
    mixed_x = lam * x + (1 - lam) * x_shuffled
    return mixed_x, y, y_shuffled, lam

# --- stratified train/val split ---
splitter = StratifiedShuffleSplit(n_splits=1, test_size=VAL_SPLIT, random_state=SEED)
train_idx, val_idx = next(splitter.split(X_train, y_train))
train_dataset = torch.utils.data.Subset(EEGDataset(X_train, y_train), train_idx)
val_dataset = torch.utils.data.Subset(EEGDataset(X_train, y_train), val_idx)
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)
test_dataset = EEGDataset(X_test, y_test)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

# --- instantiate pretrained model ---
n_channels = X_train.shape[1]
time_length = X_train.shape[2]
eeg_shape = (n_channels, time_length)
# pick patch size (same logic)
def choose_eeg_patch_size(eeg_shape, max_time_patch=32):
    channel_patch = 1
    time_length = eeg_shape[1]
    time_patch = next((d for d in range(max_time_patch, 0, -1) if time_length % d == 0), 1)
    return (channel_patch, time_patch)

patch_size = choose_eeg_patch_size(eeg_shape)
model = EEGViTPretrained(
    image_size=eeg_shape,
    patch_size=patch_size,
    num_classes=NUM_CLASSES
).to(device)

# --- loss, optimizer, scheduler ---
def make_class_weight_tensor_from_counts(counts, device):
    num_classes_local = max(counts.keys()) + 1
    weights = torch.ones(num_classes_local, device=device)
    for cls, cnt in counts.items():
        if cnt > 0:
            weights[cls] = 1.0 / cnt
    weights = weights / weights.sum() * num_classes_local
    return weights

# class weights from training split
y_train_split = y_train[train_idx]
train_counts = Counter(y_train_split.tolist())
class_weights = make_class_weight_tensor_from_counts(train_counts, device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=LR)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode="max", factor=0.5, patience=5, verbose=True)

# --- evaluation helper ---
def evaluate(model, loader):
    model.eval()
    all_preds, all_labels = [], []
    with torch.no_grad():
        for xb, yb in loader:
            xb = xb.to(device)
            yb = yb.to(device)
            logits = model(xb)
            preds = logits.argmax(dim=1)
            all_preds.append(preds.cpu().numpy())
            all_labels.append(yb.cpu().numpy())
    return np.concatenate(all_labels), np.concatenate(all_preds)

# --- training loop ---
best_val_acc = 0.0
stale = 0
history = {"train_loss": [], "train_acc": [], "val_acc": []}

for epoch in range(1, EPOCHS + 1):
    model.train()
    total_loss = 0.0
    correct = 0
    total = 0

    for xb, yb in train_loader:
        xb = xb.to(device)
        yb = yb.to(device)

        if (yb < 0).any() or (yb >= NUM_CLASSES).any():
            raise RuntimeError("Label out of range")

        mixed_x, y_a, y_b, lam = apply_mixup(xb, yb, alpha=MIXUP_ALPHA, use_mixup=True)
        logits = model(mixed_x)
        loss = lam * criterion(logits, y_a) + (1 - lam) * criterion(logits, y_b)

        optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()

        total_loss += loss.item() * xb.size(0)
        with torch.no_grad():
            orig_logits = model(xb)
            preds = orig_logits.argmax(dim=1)
            correct += (preds == yb).sum().item()
        total += xb.size(0)

    train_loss = total_loss / total
    train_acc = correct / total

    y_val, preds_val = evaluate(model, val_loader)
    val_acc = (preds_val == y_val).mean()

    scheduler.step(val_acc)

    history["train_loss"].append(train_loss)
    history["train_acc"].append(train_acc)
    history["val_acc"].append(val_acc)

    if val_acc > best_val_acc:
        best_val_acc = val_acc
        stale = 0
        torch.save(model.state_dict(), f"best_pretrained_eegvit_val{val_acc:.4f}.pth")
    else:
        stale += 1

    print(f"[Epoch {epoch:02d}] train_loss={train_loss:.4f} train_acc={train_acc:.4f} val_acc={val_acc:.4f} best={best_val_acc:.4f} stale={stale}")
    if stale >= EARLY_STOPPING_PATIENCE:
        print("Early stopping.")
        break

# --- final evaluation ---
y_true, y_pred = evaluate(model, test_loader)
acc = (y_pred == y_true).mean()
bal_acc = balanced_accuracy_score(y_true, y_pred)
print(f"Test accuracy: {acc:.4f}, balanced accuracy: {bal_acc:.4f}")
print("Test classification report:\n", classification_report(y_true, y_pred, digits=4, zero_division=0))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(7,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix (Test)")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.tight_layout()
plt.show()

# training curves
plt.figure()
plt.plot(history["train_loss"], label="train_loss")
plt.plot(history["train_acc"], label="train_acc")
plt.plot(history["val_acc"], label="val_acc")
plt.legend()
plt.title("Training curves")
plt.xlabel("Epoch")
plt.tight_layout()
plt.show()

